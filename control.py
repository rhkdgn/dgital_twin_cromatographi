import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from scipy.signal import savgol_filter, filtfilt, savgol_coeffs
from model import VirtualColumn

print("--- ğŸš€ ë””ì§€í„¸ íŠ¸ìœˆ ì—°êµ¬ í†µí•©íŒ: ë…¸í™” ì§„ë‹¨ ë° ì ì‘í˜• ë…¸ì´ì¦ˆ í•„í„°ë§ ---")

# ==========================================
# 1. ìƒí™© ì„¤ì •: ë…¸í›„í™”ëœ ê³µì¥ ë° ëœë¤ ë…¸ì´ì¦ˆ ë°œìƒ
# ==========================================
real_aging = 0.65
real_plant = VirtualColumn(N=50, V_total=10.0, Q=1.0)
real_plant.aging_factor = real_aging

# í˜„ì‹¤ ë°ì´í„° ìƒì„± (ì´ë¡ ì  ê¹¨ë—í•œ ê°’)
t_real, y_target_clean, _ = real_plant.run_simulation(t_max=100)

# [TEST] ë…¸ì´ì¦ˆ ê°•ë„ë¥¼ 0.2~0.9 ì‚¬ì´ì—ì„œ ëœë¤í•˜ê²Œ ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.
noise_level = 0.7
noise = np.random.normal(0, noise_level, size=y_target_clean.shape) 
y_target_noisy = y_target_clean + noise 

# ---------------------------------------------------------
# [ADAPTIVE LOGIC] ì‹¤ì‹œê°„ ë…¸ì´ì¦ˆ ì¸¡ì • ë° ìœˆë„ìš° ìë™ ì„¤ì •
# ---------------------------------------------------------
# 1. ë² ì´ìŠ¤ë¼ì¸(0~10ë¶„) êµ¬ê°„ì—ì„œ ì‹¤ì œ ë…¸ì´ì¦ˆ ìˆ˜ì¹˜(í‘œì¤€í¸ì°¨)ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
baseline_noise = np.std(y_target_noisy[0:100]) 

# 2. ì¸¡ì •ëœ ë…¸ì´ì¦ˆì— ë§ì¶° ìœˆë„ìš° ê¸¸ì´ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. (Mapping Function)
auto_window = int(60 * baseline_noise + 9)
if auto_window % 2 == 0: auto_window += 1  # ë¬´ì¡°ê±´ í™€ìˆ˜ ìœ ì§€

# 3. ê²°ì •ëœ ìë™ ìœˆë„ìš°ë¡œ í•„í„° ì ìš©
# SG í•„í„°ì— ì‚¬ìš©ë˜ëŠ” ìˆ˜í•™ì  ê³„ìˆ˜(Coefficients)ë¥¼ ë¨¼ì € ì¶”ì¶œí•©ë‹ˆë‹¤.
coeffs = savgol_coeffs(window_length=auto_window, polyorder=3)

# filtfiltë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ë’¤ë¡œ ë‘ ë²ˆ í•„í„°ë§í•´ ìœ„ìƒ ì§€ì—°ì„ 0ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
# filtfilt(ê³„ìˆ˜, ë¶„ëª¨ê³„ìˆ˜[ë³´í†µ 1.0], ë°ì´í„°) ìˆœì„œì…ë‹ˆë‹¤.
y_filtered = filtfilt(coeffs, [1.0], y_target_noisy)
# ---------------------------------------------------------

print(f"1. ìƒí™© ë°œìƒ: ë…¸í™”ë„({real_aging})")
print(f"   >> ë…¸ì´ì¦ˆ ê°ì§€ê¸°: Ïƒ={baseline_noise:.3f} ê°ì§€ -> ìœˆë„ìš° {auto_window} ì„¤ì •")

# ==========================================
# 2. AI ì§„ë‹¨ (í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ë³´ê³  ì •ë‹µ ì¶”ì¸¡)
# ==========================================
def calculate_error(guess):
    current_guess = guess[0]
    if current_guess <= 0.0 or current_guess > 2.0:
        return 999999999.0
    sim = VirtualColumn(N=50, V_total=10.0, Q=1.0)
    sim.aging_factor = current_guess
    _, y_sim, _ = sim.run_simulation(t_max=100)
    # AIëŠ” í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    return np.mean(((y_filtered - y_sim)**2) * (y_filtered + 1.0))

print("   >> AIê°€ ì ì‘í˜• í•„í„°ë¥¼ í†µí•´ ë…¸í™”ë„ë¥¼ ì—­ì¶”ì  ì¤‘...")
search_grid = np.linspace(0.1, 2.0, 20)
best_guess = 1.0
min_err = 999999999.0

for g in search_grid:
    err = calculate_error([g])
    if err < min_err:
        min_err = err
        best_guess = g

res = minimize(calculate_error, [best_guess], method='Nelder-Mead', tol=1e-5)
ai_estimated_aging = res.x[0]

print(f"2. AI ì§„ë‹¨ ì™„ë£Œ: ìµœì¢… Aging Factor {ai_estimated_aging:.4f} ì¶”ì •")

# ==========================================
# 3. ê³¨ë“ íƒ€ì„ ì˜ˆì¸¡ ë° ì œì–´ ëª…ë ¹
# ==========================================
ai_model = VirtualColumn(N=50, V_total=10.0, Q=1.0)
ai_model.aging_factor = ai_estimated_aging
t_sim, y_sim, _ = ai_model.run_simulation(t_max=100)

adaptive_margin = 9.0 - (ai_estimated_aging * 5.0)
peak_index = np.argmax(y_sim)
peak_time = t_sim[peak_index]
optimal_cut_point = peak_time - adaptive_margin
print(f"âœ… ì§€ëŠ¥í˜• ì œì–´: ë…¸í™”ë„ {ai_estimated_aging:.3f}ì— ë§ì¶° ë§ˆì§„ì„ {adaptive_margin:.2f}ë¶„ìœ¼ë¡œ ìë™ ì¡°ì •í–ˆìŠµë‹ˆë‹¤.")
# ==========================================
# 4. ê²°ê³¼ ì‹œê°í™” (ëª¨ë“  ì‹œê°í™” ìš”ì†Œ ìœ ì§€)
# ==========================================
new_plant = VirtualColumn(N=50, V_total=10.0, Q=1.0)
new_plant.aging_factor = 1.0
t_new, y_new, _ = new_plant.run_simulation(t_max=100)

new_peak_t, new_peak_y = t_new[np.argmax(y_new)], np.max(y_new)
real_peak_t, real_peak_y = t_real[np.argmax(y_target_clean)], np.max(y_target_clean)

plt.figure(figsize=(14, 7))

# (1) ìƒˆ ì œí’ˆ ìƒíƒœ (íšŒìƒ‰ ì ì„ )
plt.plot(t_new, y_new, color='gray', linestyle=':', label='Brand New Column (Aging=1.0)', alpha=0.5)

# (2) ë…¸ì´ì¦ˆ ì„ì¸ ì›ë³¸ (ë§¤ìš° ì—°í•œ ë¹¨ê°„ìƒ‰)
plt.plot(t_real, y_target_noisy, color='red', alpha=0.1, label=f'Raw Noisy Data ({noise_level})')

# (3) [NEW] ì ì‘í˜• í•„í„°ë¡œ í´ì§„ ì‹ í˜¸ (ì§„í•œ ë¹¨ê°„ ì‹¤ì„ )
plt.plot(t_real, y_filtered, color='red', linewidth=2, label=f'Adaptive Filtered (Win={auto_window})')

# (4) AIê°€ ì œì–´ìš©ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•œ ëª¨ë¸ (íŒŒë€ ì ì„ )
plt.plot(t_sim, y_sim, 'b--', linewidth=2, label=f'AI Model (Aging={ai_estimated_aging:.3f})')

# (5) ì œì–´ ëª…ë ¹ ì„  ë° ê¸°ì¡´ ê³„íš ì„ 
plt.axvline(x=55, color='gray', linestyle='--', linewidth=1, label='Legacy Plan (55min)', alpha=0.5)
plt.axvline(x=optimal_cut_point, color='blue', linestyle='--', linewidth=2, label=f'AI Control ({optimal_cut_point:.1f}min)')

# --- í”¼í¬ ì´ë™ í™”ì‚´í‘œ ë° í•˜ì´ë¼ì´íŠ¸ ---
plt.annotate('', xy=(real_peak_t, real_peak_y), xytext=(new_peak_t, new_peak_y),
             arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=10))
plt.text((real_peak_t + new_peak_t)/2, (real_peak_y + new_peak_y)/2 + 0.3, 
         'Peak Shift due to Aging', ha='center', fontsize=11, fontweight='bold')

plt.text(real_peak_t - 15, real_peak_y * 0.8, 'AI SAVED:\nAdjusted for Aging', 
         color='blue', fontweight='bold', fontsize=12, ha='center')

plt.title(f"Adaptive Digital Twin: Noise Ïƒ={baseline_noise:.2f} -> Auto Window {auto_window}", fontsize=16)
plt.xlabel("Time (min)", fontsize=12)
plt.ylabel("Target Concentration", fontsize=12)
plt.legend(loc='upper right')
plt.grid(True, alpha=0.3)
plt.tight_layout()
# ==========================================
# 5. ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ (ì„±ì í‘œ ê³„ì‚°) - ê°€ë³€ ë§ˆì§„ ëŒ€ì‘íŒ
# ==========================================

# (1) ë…¸í™”ë„ ì§„ë‹¨ ì˜¤ì°¨ìœ¨ (%)
aging_error_pct = abs(real_aging - ai_estimated_aging) / real_aging * 100

# (2) í”¼í¬ ì‹œê°„ ì˜ˆì¸¡ ì˜¤ì°¨ (ì´ˆ ë‹¨ìœ„)
true_peak_time = t_real[np.argmax(y_target_clean)]
peak_time_diff_sec = abs(true_peak_time - peak_time) * 60 

# (3) ì œì–´ ëª…ë ¹ ì •í™•ë„ ê³„ì‚° (ê°€ë³€ ë§ˆì§„ ëŒ€ì‘)
# ì •ë‹µì§€: ì‹¤ì œ ë…¸í™”ë„(real_aging)ë¥¼ ë„£ì—ˆì„ ë•Œ ë‚˜ì™€ì•¼ í•˜ëŠ” ë§ˆì§„
true_adaptive_margin = 9.0 - (real_aging * 5.0)
true_golden_time = true_peak_time - true_adaptive_margin # ì´ê²ƒì´ ì§„ì§œ 'ì •ë‹µ' ì‹œê°„ì…ë‹ˆë‹¤.

# AIì˜ ëª…ì¤‘ ì˜¤ì°¨ (ì´ˆ ë‹¨ìœ„)
control_error_sec = abs(optimal_cut_point - true_golden_time) * 60

# (4) ê¸°ì¡´ ë°©ì‹(55ë¶„ ê³ ì •) ëŒ€ë¹„ ê°œì„  íš¨ê³¼
legacy_error = abs(55.0 - true_golden_time)
ai_error = abs(optimal_cut_point - true_golden_time)
ai_improvement_min = legacy_error - ai_error

print("\n" + "="*50)
print("ğŸ¯ [ë””ì§€í„¸ íŠ¸ìœˆ ì‹œìŠ¤í…œ ìµœì¢… ì„±ì í‘œ - ê°€ë³€ ë§ˆì§„ ëª¨ë“œ]")
print("-"*50)
print(f"1. ë…¸í™”ë„ ì§„ë‹¨ ì •í™•ë„  : {100 - aging_error_pct:.4f} %")
print(f"   (ì‹¤ì œ: {real_aging:.2f} | AIì¶”ì •: {ai_estimated_aging:.4f})")
print(f"2. í”¼í¬ ì‹œê°„ ì˜ˆì¸¡ ì˜¤ì°¨ : {peak_time_diff_sec:.2f} ì´ˆ")
print(f"3. ì œì–´ ëª…ë ¹ ì •í™•ë„    : AIê°€ ì‹¤ì œ ê³¨ë“ íƒ€ì„ì„ {control_error_sec:.2f}ì´ˆ ì°¨ì´ë¡œ ëª…ì¤‘í•¨")
print(f"4. ê³µì • ê°œì„  íš¨ê³¼      : ê¸°ì¡´ ë°©ì‹ ëŒ€ë¹„ ì•½ {ai_improvement_min:.1f}ë¶„ ë” ì •í™•í•˜ê²Œ ìˆ˜ê±° ì‹œì‘")
print("="*50)
plt.show()
